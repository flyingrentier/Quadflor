# experiments for final run of LSTM
# single fold
# python run.py -f lstm --onehot -k file_paths.json --fixed_folds --folds=1 -v --batch_size=256 -e 200 --val-size=0.2 -C ../../Experiments/lstm_experiments_final.cfg -o lstm_experiments_final_singlefold.csv --optimize_threshold --patience=10 --tf-model-path=<path/to/temporary/folder> --max_features=250 --num_steps_before_validation=2000 --embedding_size=300 --pretrained_embeddings=<path/to/embedding/file/in/w2v/format> --trainable_embeddings --bidirectional --aggregate_output=attention
# crossvalidation
# # python run.py -f lstm --onehot -k file_paths_ks.json --fixed_folds --folds=10 -v --batch_size=256 -e 200 --val-size=0.2 -C ../../Experiments/lstm_experiments_final.cfg -o lstm_experiments_final_crossval.csv --optimize_threshold --patience=10 --tf-model-path=<path/to/temporary/folder> --max_features=250 --num_steps_before_validation=2000 --embedding_size=300 --pretrained_embeddings=<path/to/embedding/file/in/w2v/format> --trainable_embeddings --bidirectional --aggregate_output=attention
# PubMed
-K pubmed --extra_samples_factor=1 --learning_rate=0.001 --dropout=0.75 --hidden_layers 1536
-K pubmed --extra_samples_factor=2 --learning_rate=0.001 --dropout=0.75 --hidden_layers 1536
-K pubmed --extra_samples_factor=4 --learning_rate=0.001 --dropout=0.75 --hidden_layers 1536
-K pubmed --extra_samples_factor=8 --learning_rate=0.001 --dropout=0.75 --hidden_layers 1536
-K pubmed --extra_samples_factor=100 --learning_rate=0.001 --dropout=0.75 --hidden_layers 1536
# EconBiz
-K econbiz --extra_samples_factor=1 --learning_rate=0.001 --dropout=0.5 --hidden_layers 1536
-K econbiz --extra_samples_factor=2 --learning_rate=0.001 --dropout=0.5 --hidden_layers 1536
-K econbiz --extra_samples_factor=4 --learning_rate=0.001 --dropout=0.5 --hidden_layers 1536
-K econbiz --extra_samples_factor=8 --learning_rate=0.001 --dropout=0.5 --hidden_layers 1536
-K econbiz --extra_samples_factor=100 --learning_rate=0.001 --dropout=0.5 --hidden_layers 1536
